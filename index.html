<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, .initial-scale=1">
  <title>Nerfies: Deformable Neural Radiance Fields</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="https://www.nus.edu.sg/images/favicon.ico" type="image/x-icon">


  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!--
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>
-->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Nerfies: Deformable Neural Radiance Fields</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://kodaikawamura.github.io/kodaikawamura/">Kodai Kawamura*</a><sup>*1,2</sup>,</span>
            <!--
            <span class="author-block">
              <a href="https://utkarshsinha.com">Yuta Goto*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Rintaro Yanagi</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Hirokatsu Kataoka</a><sup>3,4</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com">Go Irie</a><sup>1</sup>,
            </span>-->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tokyo University of Science,</span>
            <span class="author-block"><sup>2</sup>National University of Singapore,</span>
            <span class="author-block"><sup>3</sup>National Institute of Advanced Industrial Science and Technology (AIST),</span>
            <span class="author-block"><sup>4</sup>Visual Geometry Group, University of Oxford</span>
            <span class="author-block">* equal contribution.</span>
          </div>

          <div class="is-size-4 publication-authors">
                    <b>Preprint 2025</b>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. 
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. 
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
                  
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Pre-trained Vision-Language Models (VLMs) exhibit strong generalization capabilities, enabling them to recognize a wide range of objects across diverse domains without additional training. 
            However, they often retain irrelevant information beyond the requirements of specific target downstream tasks, raising concerns about computational efficiency and potential information leakage. 
            This has motivated growing interest in approximate unlearning, which aims to selectively remove unnecessary knowledge while preserving overall model performance.
            Existing approaches to approximate unlearning have primarily focused on class unlearning, where a VLM is retrained to fail to recognize specified object classes while maintaining accuracy for others. 
            However, merely forgetting object classes is often insufficient in practical applications. 
            For instance, an autonomous driving system should accurately recognize real cars, while avoiding misrecognition of illustrated cars depicted in roadside advertisements as real cars, which could be hazardous. 
            In this paper, we introduce Approximate Domain Unlearning (ADU), a novel problem setting that requires reducing recognition accuracy for images from specified domains (e.g., illustration) while preserving accuracy for other domains (e.g., real).           
            ADU presents new technical challenges: due to the strong domain generalization capability of pre-trained VLMs, domain distributions are highly entangled in the feature space, making naive approaches based on penalizing target domains ineffective. 
            To tackle this limitation, we propose a novel approach that explicitly disentangles domain distributions and adaptively captures instance-specific domain information.
             Extensive experiments on three multi-domain benchmark datasets demonstrate that our approach significantly outperforms strong baselines built upon state-of-the-art VLM tuning techniques, paving the way for practical and fine-grained unlearning in VLMs.
          </p>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Approximate Domain Unlearning</h2>
        <div class="content has-text-centered">
            <img src="./static/images/attention_map.map" alt="Illustration of Approximate Domain Unlearning (ADU)" width="80%">
        </div>
        <div class="content has-text-justified">
            <p>Approximate Domain Unlearning (ADU) is a novel approximate unlearning problem introduced in this paper. Unlike existing approximate class unlearning tasks, ADU requires retraining a pre-trained Vision-Language Model (VLM) so that it cannot recognize images from specified domains (painting, clipart, sketch in the figure) while preserving its ability to recognize images from other domains (real in the figure). </p>
        </div>
        <h3 class="title is-4">Problem Setting</h3>
        <div class="content has-text-centered">
            <img src="./static/images/algorithm_v2.png" alt="Reward-Adaptive Time-Rescaled Langevin SDE" width="50%">
        </div>
        <div class="content has-text-justified">
          <p>
            Given a set of training data
            \( \{(\mathbf{x}, y, d)\} \),
            where \( \mathbf{x} \in \mathcal{X} \) represents an input image,
            \( y \in \mathcal{C} \) is the class label, and
            \( d \in \mathcal{D} \) is the domain label, with
            \( \mathcal{C} \) and \( \mathcal{D} \) denoting the sets of all classes
            and domains, respectively.
          </p>

          <p class="math-block">
            We define
            \( \mathcal{D}_{\text{memorize}} \subset \mathcal{D} \)
            as the set of domains to be preserved and
            \( \mathcal{D}_{\text{forget}} = \mathcal{D} \setminus \mathcal{D}_{\text{memorize}} \)
            as the set of domains to be forgotten.
          </p>

          <p class="math-block">
            Our goal is to retrain a pre-trained vision-language model \( f \) to
            maintain the classification accuracy for
            \( \{(\mathbf{x}, y, d) \mid d \in \mathcal{D}_{\text{memorize}}\} \),
            while reducing it for
            \( \{(\mathbf{x}, y, d) \mid d \in \mathcal{D}_{\text{forget}}\} \).
          </p>
        </div>
    </div>
</section>

    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p>
                            Website adapted from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a> and <a href="https://joonghyuk.com/instantdrag-web/">InstantDrag</a>.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>

<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                    <p>
                        Website adapted from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a> and <a href="https://joonghyuk.com/instantdrag-web/">InstantDrag</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>


</body>
</html>
